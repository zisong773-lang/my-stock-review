import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import os
import json
import textwrap
from datetime import datetime, timedelta

# --- åŸºç¡€åº“æ£€æŸ¥ ---
try:
    import yfinance as yf
    import numpy as np
    import s3fs # æ–°å¢ï¼šå¼•å…¥ S3 æ–‡ä»¶ç³»ç»Ÿåº“
except ImportError as e:
    st.error(f"ç¼ºå°‘å¿…è¦åº“ï¼Œè¯·å…ˆå®‰è£…: {e}\nè¯·ç¡®ä¿å·²æ‰§è¡Œ: pip install s3fs yfinance plotly pandas")
    st.stop()

# --- é¡µé¢è®¾ç½® ---
st.set_page_config(page_title="è‚¡ä»·å¤ç›˜ (äº‘ç«¯åŒæ­¥ç‰ˆ)", layout="wide")

# --- äº‘ç«¯è¿æ¥åˆå§‹åŒ– ---
# å°è¯•ä» secrets è·å– AWS é…ç½®
if "aws" in st.secrets:
    try:
        # åˆå§‹åŒ– S3 æ–‡ä»¶ç³»ç»Ÿ
        fs = s3fs.S3FileSystem(
            key=st.secrets["aws"]["aws_access_key_id"],
            secret=st.secrets["aws"]["aws_secret_access_key"]
        )
        BUCKET_NAME = st.secrets["aws"]["bucket_name"]
        HISTORY_DIR = f"{BUCKET_NAME}/history_charts"
        
        # ç¡®ä¿äº‘ç«¯ç›®å½•å­˜åœ¨ (S3å…¶å®æ˜¯å¹³é“ºçš„ï¼Œè¿™æ­¥ä¸»è¦æ˜¯æ£€æŸ¥æƒé™)
        if not fs.exists(HISTORY_DIR):
            fs.makedirs(HISTORY_DIR)
            
        USE_CLOUD = True
    except Exception as e:
        st.error(f"AWS S3 è¿æ¥å¤±è´¥ï¼Œå°†æ— æ³•ä¿å­˜åˆ°äº‘ç«¯: {e}")
        USE_CLOUD = False
else:
    st.warning("âš ï¸ æœªæ£€æµ‹åˆ° [.streamlit/secrets.toml] é…ç½®ï¼Œè¯·é…ç½® AWS å¯†é’¥ä»¥å¯ç”¨äº‘åŒæ­¥ã€‚")
    USE_CLOUD = False


# --- è¾…åŠ©å‡½æ•°å®šä¹‰ ---
def process_text_smart(text, wrap_width):
    if not isinstance(text, str): return str(text)
    lines = text.split('\n')
    processed_lines = []
    for line in lines:
        line = line.strip()
        if not line: continue
        line = line.replace("<br>", "\n")
        sub_lines = line.split("\n")
        for sl in sub_lines:
            wrapped = textwrap.wrap(sl, width=wrap_width)
            processed_lines.extend(wrapped)
    return "<br>".join(processed_lines)

def generate_mock_data(start, end):
    dates = pd.date_range(start=start, end=end, freq='B')
    n = len(dates)
    if n == 0: return None
    np.random.seed(42)
    returns = np.random.normal(loc=0.0003, scale=0.015, size=n)
    price = 3000 * np.cumprod(1 + returns)
    df = pd.DataFrame(index=dates)
    df['Close'] = price
    df['Open'] = df['Close'].shift(1).fillna(price[0]) * (1 + np.random.randn(n)*0.005)
    return df.round(0)

def load_data_from_excel(file):
    try:
        df = pd.read_excel(file, sheet_name='Prices')
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        return df
    except: 
        return None

def get_stock_data(source, ticker, start, end, uploaded_file):
    if source == "Yahoo Finance (å®ç›˜æ•°æ®)":
        start_str = start.strftime('%Y-%m-%d')
        end_str = end.strftime('%Y-%m-%d')
        try:
            with st.spinner("æ­£åœ¨è¿æ¥ Yahoo..."):
                dat = yf.Ticker(ticker)
                df = dat.history(start=start_str, end=end_str, auto_adjust=True)
            if df.empty:
                st.error("âŒ Yahoo è¿”å›ç©ºæ•°æ®")
                return None
            if df.index.tz is not None: df.index = df.index.tz_localize(None)
            return df
        except Exception as e:
            st.error(f"è¿æ¥å¤±è´¥: {e}")
            return None
    elif source == "Excelæ–‡ä»¶ (Pricesè¡¨)":
        return load_data_from_excel(uploaded_file) if uploaded_file else None
    else:
        return generate_mock_data(start, end)

def find_col_in_list(columns, keywords, exclude_keywords=None):
    for col in columns:
        col_str = str(col)
        if exclude_keywords and any(ex in col_str for ex in exclude_keywords):
            continue
        for kw in keywords:
            if kw in col_str:
                return col
    return None

def extract_table_dynamically(df, required_keywords, name="Table"):
    def check_columns(cols):
        found_cols = {}
        for key, (kws, ex_kws) in required_keywords.items():
            found = find_col_in_list(cols, kws, ex_kws)
            if found:
                found_cols[key] = found
            else:
                return None
        return found_cols

    found_cols = check_columns(df.columns)
    if found_cols:
        return df, found_cols

    max_scan = min(len(df), 100)
    for i in range(max_scan):
        row_values = df.iloc[i].astype(str).tolist()
        is_header_row = True
        for key, (kws, ex_kws) in required_keywords.items():
            if not any(kw in cell for cell in row_values for kw in kws):
                is_header_row = False
                break
        
        if is_header_row:
            new_df = df.iloc[i+1:].copy()
            new_df.columns = df.iloc[i]
            new_found_cols = check_columns(new_df.columns)
            if new_found_cols:
                return new_df, new_found_cols
    
    return None, None

def aggregate_details(df, group_keys, detail_col, output_detail_name="Detail"):
    if not detail_col: return df
    for k in group_keys:
        df[k] = df[k].ffill()
    
    def join_text(series):
        texts = [str(s).strip() for s in series if pd.notna(s) and str(s).strip() != '']
        if not texts: return None
        if len(texts) == 1: return texts[0]
        return "<br>".join([f"â€¢ {t}" for t in texts])

    agg_dict = {detail_col: join_text}
    temp = df.groupby(group_keys, as_index=False).agg(agg_dict)
    temp = temp.rename(columns={detail_col: output_detail_name})
    return temp

def parse_uploaded_excel(file):
    try:
        all_sheets = pd.read_excel(file, sheet_name=None)
        events_list = []
        phases_list = []
        
        event_rules = {
            'event': (['ä¸»è¦é©±åŠ¨', 'Event'], None),
            'date': (['æ—¥æœŸ', 'Date', 'æ—¶é—´'], ['èµ·å§‹', 'å¼€å§‹', 'Start', 'ç»“æŸ', 'End'])
        }
        
        phase_rules = {
            'phase': (['é˜¶æ®µæ¦‚è¿°', 'Phase'], None),
            'start': (['èµ·å§‹æ—¥æœŸ', 'å¼€å§‹æ—¥æœŸ', 'Start'], None),
            'end': (['ç»“æŸæ—¥æœŸ', 'End'], None)
        }

        for sheet_name, df in all_sheets.items():
            df.columns = df.columns.astype(str).str.strip()
            
            # 1. æå–äº‹ä»¶è¡¨
            e_df, e_cols = extract_table_dynamically(df, event_rules, "Events")
            if e_df is not None:
                hover_col = find_col_in_list(e_df.columns, ['è¯¦ç»†è§£é‡Š', 'å› æœé“¾', 'Detailed'])
                cols_to_keep = [e_cols['date'], e_cols['event']]
                if hover_col: cols_to_keep.append(hover_col)
                temp = e_df[cols_to_keep].copy()
                
                if hover_col:
                    temp = aggregate_details(temp, group_keys=[e_cols['date'], e_cols['event']], detail_col=hover_col, output_detail_name='è¯¦ç»†è§£é‡Š')
                
                temp = temp.rename(columns={e_cols['date']: 'Date', e_cols['event']: 'ä¸»è¦é©±åŠ¨'})
                temp['Date'] = pd.to_datetime(temp['Date'], errors='coerce')
                temp = temp.dropna(subset=['Date'])
                if not temp.empty:
                    events_list.append(temp)
            
            # 2. æå–é˜¶æ®µè¡¨
            p_df, p_cols = extract_table_dynamically(df, phase_rules, "Phases")
            if p_df is not None:
                hover_col = find_col_in_list(p_df.columns, ['å…³é”®å› ç´ ', 'è¦ç‚¹', 'Key Factors'])
                cols_to_keep = [p_cols['start'], p_cols['end'], p_cols['phase']]
                if hover_col: cols_to_keep.append(hover_col)
                temp = p_df[cols_to_keep].copy()
                
                if hover_col:
                    temp = aggregate_details(temp, group_keys=[p_cols['start'], p_cols['end'], p_cols['phase']], detail_col=hover_col, output_detail_name='å…³é”®å› ç´ ')
                
                temp = temp.rename(columns={p_cols['start']: 'Start date', p_cols['end']: 'End date', p_cols['phase']: 'é˜¶æ®µæ¦‚è¿°'})
                temp['Start date'] = pd.to_datetime(temp['Start date'], errors='coerce')
                temp['End date'] = pd.to_datetime(temp['End date'], errors='coerce')
                temp = temp.dropna(subset=['Start date'])
                if not temp.empty:
                    phases_list.append(temp)

        events_df = pd.concat(events_list, ignore_index=True) if events_list else None
        phases_df = pd.concat(phases_list, ignore_index=True) if phases_list else None
        return events_df, phases_df

    except Exception as e:
        import traceback
        st.error(f"è§£æ Excel å‡ºé”™: {e}")
        st.text(traceback.format_exc())
        return None, None

# ==============================================================================
# ä¸»ç¨‹åºå…¥å£
# ==============================================================================

st.sidebar.title("ğŸ›ï¸ ç³»ç»Ÿæ¨¡å¼")
app_mode = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", ["ğŸš€ ç”Ÿæˆæ–°å›¾è¡¨", "ğŸ“‚ æµè§ˆå†å²è®°å½• (äº‘ç«¯)"])

if app_mode == "ğŸš€ ç”Ÿæˆæ–°å›¾è¡¨":
    st.title("ğŸ“ˆ 2025 è‚¡ä»·å¤ç›˜ç³»ç»Ÿï¼šäº‘ç«¯æ™ºèƒ½ç‰ˆ")
    st.markdown("---")

    # --- 0. ä»£ç†è®¾ç½® ---
    st.sidebar.header("0. ç½‘ç»œä»£ç†è®¾ç½®")
    enable_proxy = st.sidebar.checkbox("å¼€å¯ä»£ç†è¿æ¥", value=True)
    proxy_address = st.sidebar.text_input("ä»£ç†åœ°å€", value="http://127.0.0.1:17890")
    if enable_proxy:
        os.environ["HTTP_PROXY"] = proxy_address
        os.environ["HTTPS_PROXY"] = proxy_address
    else:
        os.environ.pop("HTTP_PROXY", None)
        os.environ.pop("HTTPS_PROXY", None)

    # --- 1. æ•°æ®æ¥æº ---
    st.sidebar.header("1. æ•°æ®æ¥æº")
    data_source = st.sidebar.radio("é€‰æ‹©æ¨¡å¼", ["Yahoo Finance (å®ç›˜æ•°æ®)", "Excelæ–‡ä»¶ (Pricesè¡¨)", "ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (æµ‹è¯•ç”¨)"])

    # --- 2. ç»˜å›¾å‚æ•° ---
    st.sidebar.header("2. ç»˜å›¾å‚æ•°")
    default_start = pd.to_datetime("2024-12-23")
    default_end = min(pd.to_datetime("2025-12-23"), datetime.today())
    ticker = st.sidebar.text_input("è‚¡ç¥¨ä»£ç ", value="6324.T")
    start_date = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", value=default_start)
    end_date_input = st.sidebar.date_input("ç»“æŸæ—¥æœŸ", value=default_end, max_value=datetime.today())
    end_date_final = end_date_input + timedelta(days=1)

    # --- 3. è§†è§‰ä¸æ’ç‰ˆå¾®è°ƒ ---
    st.sidebar.header("3. è§†è§‰ä¸æ’ç‰ˆå¾®è°ƒ")
    export_scale = st.sidebar.radio("å¯¼å‡ºæ¸…æ™°åº¦/å€ç‡", [1, 2, 3], index=0, format_func=lambda x: f"{x}å€", horizontal=True)
    phase_font_size = st.sidebar.slider("é¡¶éƒ¨é˜¶æ®µå­—ä½“å¤§å°", 10, 80, 20)
    event_font_size = st.sidebar.slider("ä¸‹æ–¹äº‹ä»¶å­—ä½“å¤§å°", 8, 60, 16)
    phase_label_y = st.sidebar.slider("é˜¶æ®µæ ‡ç­¾åŸºç¡€é«˜åº¦", 1.0, 1.3, 1.02, 0.01)
    phase_stagger = st.sidebar.checkbox("å¼€å¯é¡¶éƒ¨æ ‡ç­¾é”™è½", value=True)
    phase_stagger_gap = st.sidebar.slider("é¡¶éƒ¨é”™è½é«˜åº¦å·®", 0.01, 0.15, 0.05)
    label_wrap_width = st.sidebar.slider("æ ‡ç­¾æ¢è¡Œå­—æ•°", 5, 30, 10)
    hover_wrap_width = st.sidebar.slider("æ‚¬æµ®æ–‡å­—æ¢è¡Œå­—æ•°", 20, 80, 40)
    arrow_len_base = st.sidebar.slider("å¼•çº¿åŸºç¡€é•¿åº¦", 20, 150, 50)
    stagger_steps = st.sidebar.slider("ä¸‹æ–¹é˜²é‡å é˜¶æ¢¯æ•°", 3, 10, 6)
    stagger_gap = st.sidebar.slider("ä¸‹æ–¹é˜¶æ¢¯å‚ç›´é—´è·", 10, 100, 50)
    y_headroom = st.sidebar.slider("é¡¶éƒ¨å¼ºåˆ¶ç•™ç™½ (%)", 0, 100, 7)
    bg_opacity = st.sidebar.slider("æ ‡ç­¾èƒŒæ™¯é€æ˜åº¦", 0.1, 1.0, 0.8)
    bottom_margin = st.sidebar.slider("åº•éƒ¨ç•™ç™½é«˜åº¦", 50, 150, 80)
    top_margin = st.sidebar.slider("é¡¶éƒ¨ç•™ç™½é«˜åº¦", 100, 300, 150)

    # --- 4. ä¸Šä¼ æ–‡ä»¶ ---
    st.sidebar.header("4. ä¸Šä¼ æ–‡ä»¶")
    uploaded_file = st.sidebar.file_uploader("ä¸Šä¼  Excel (ä¸­æ–‡ç‰ˆ)", type=["xlsx"])

    # --- æ ¸å¿ƒå¤„ç†é€»è¾‘ ---
    if uploaded_file or data_source == "ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® (æµ‹è¯•ç”¨)":
        stock_df = get_stock_data(data_source, ticker, start_date, end_date_final, uploaded_file)
        
        if stock_df is not None and not stock_df.empty:
            events_df, phases_df = None, None
            if uploaded_file:
                events_df, phases_df = parse_uploaded_excel(uploaded_file)
            
            if uploaded_file and events_df is None and phases_df is None:
                st.warning("âš ï¸ æœªèƒ½è¯†åˆ«Excelå†…å®¹ã€‚")
            else:
                try:
                    fig = go.Figure()
                    # 1. ç»˜åˆ¶è‚¡ä»·
                    fig.add_trace(go.Scatter(x=stock_df.index, y=stock_df['Close'], mode='lines', name=f"{ticker} æ”¶ç›˜ä»·", line=dict(color='#1976D2', width=2.5), line_shape='spline'))
                    data_start, data_end = stock_df.index.min(), stock_df.index.max()

                    # 2. ç»˜åˆ¶é˜¶æ®µ
                    if phases_df is not None and not phases_df.empty:
                        phase_colors = ["rgba(255,99,132,0.12)", "rgba(54,162,235,0.12)", "rgba(255,206,86,0.15)", "rgba(75,192,192,0.12)"]
                        target_col = find_col_in_list(phases_df.columns, ['é˜¶æ®µæ¦‚è¿°'])
                        for i, row in phases_df.iterrows():
                            p_start = max(row['Start date'], data_start)
                            p_end = min(row['End date'], data_end)
                            if p_start < p_end:
                                mid_point = p_start + (p_end - p_start) / 2
                                fig.add_vrect(x0=p_start, x1=p_end, fillcolor=phase_colors[i % 4], layer="below", line_width=0)
                                raw_text = str(row.get(target_col, ''))
                                wrapped_text = process_text_smart(raw_text, label_wrap_width)
                                hover_col = find_col_in_list(phases_df.columns, ['å…³é”®å› ç´ ', 'è¦ç‚¹', 'Key Factors'])
                                hover_text_raw = str(row.get(hover_col, '')) if hover_col else raw_text
                                hover_text = process_text_smart(hover_text_raw, hover_wrap_width)
                                current_phase_y = phase_label_y
                                if phase_stagger: current_phase_y += (i % 2) * phase_stagger_gap
                                fig.add_annotation(x=mid_point, y=current_phase_y, yref="paper", text=f"<b>{wrapped_text}</b>", hovertext=hover_text, showarrow=False, font=dict(size=phase_font_size, color="#555"), bgcolor="rgba(255,255,255,0.8)", borderpad=3, captureevents=True)

                    # 3. ç»˜åˆ¶äº‹ä»¶
                    if events_df is not None and not events_df.empty:
                        events_df = events_df.sort_values('Date').reset_index(drop=True)
                        label_col = find_col_in_list(events_df.columns, ['ä¸»è¦é©±åŠ¨'])
                        for i, row in events_df.iterrows():
                            event_date = row['Date']
                            if data_start <= event_date <= data_end:
                                try:
                                    idx = stock_df.index.get_indexer([event_date], method='nearest')[0]
                                    curr = stock_df.index[idx]
                                    vals = stock_df.loc[curr]
                                    close_p = vals['Close'].iloc[0] if isinstance(vals['Close'], pd.Series) else vals['Close']
                                    open_p = vals['Open'].iloc[0] if isinstance(vals['Open'], pd.Series) else vals['Open']
                                    y_anchor = close_p
                                    is_rising = close_p >= open_p
                                    ay_dir = 1 if is_rising else -1
                                    color = "#D32F2F" if is_rising else "#00796B"
                                    stagger_level = i % stagger_steps 
                                    current_arrow_len = arrow_len_base + (stagger_level * stagger_gap)
                                    txt = str(row.get(label_col, ''))
                                    formatted = process_text_smart(txt, label_wrap_width)
                                    hover_col = find_col_in_list(events_df.columns, ['è¯¦ç»†è§£é‡Š', 'å› æœé“¾', 'Detailed'])
                                    hover_text_raw = str(row.get(hover_col, '')) if hover_col else txt
                                    hover_formatted = process_text_smart(hover_text_raw, hover_wrap_width)
                                    fig.add_annotation(x=curr, y=y_anchor, text=f"<b>{formatted}</b>", hovertext=hover_formatted, showarrow=True, arrowhead=2, arrowwidth=1.5, arrowcolor=color, ax=0, ay=current_arrow_len * ay_dir, font=dict(size=event_font_size, color="#333"), bgcolor=f"rgba(255,255,255,{bg_opacity})", bordercolor=color, borderwidth=1, borderpad=3, hoverlabel=dict(bgcolor="white", font=dict(size=event_font_size)), captureevents=True)
                                except: pass

                    # 4. å¸ƒå±€
                    y_max = stock_df['Close'].max()
                    y_min = stock_df['Close'].min()
                    range_max = y_max * (1 + y_headroom / 100)
                    range_min = y_min * 0.95
                    fig.update_layout(title=dict(text=f"{ticker} æ”¶ç›˜ä»·è¶‹åŠ¿å¤ç›˜", x=0.5, font=dict(size=22)), yaxis_title="æ”¶ç›˜ä»· (JPY)", height=950, xaxis_rangeslider_visible=False, template="plotly_white", margin=dict(t=top_margin, r=50, b=bottom_margin), plot_bgcolor='rgba(250,250,250,1)', hovermode="x unified", dragmode="pan")
                    fig.update_xaxes(tickformat="%yå¹´%-mæœˆ", dtick="M1", showgrid=True, gridcolor='rgba(0,0,0,0.05)')
                    fig.update_yaxes(range=[range_min, range_max], showgrid=True, gridcolor='rgba(0,0,0,0.05)')

                    st.plotly_chart(fig, use_container_width=True, config={'editable': True, 'scrollZoom': True, 'toImageButtonOptions': {'format': 'png', 'filename': f'{ticker}_å¤ç›˜åˆ†æ', 'height': 950 * export_scale, 'width': 1600 * export_scale, 'scale': 1}})

                    # === æ–°å¢ï¼šäº‘ç«¯ä¿å­˜åŠŸèƒ½ ===
                    st.markdown("### ğŸ’¾ ä¿å­˜åˆ°äº‘ç«¯")
                    col_save_1, col_save_2 = st.columns([3, 1])
                    with col_save_1:
                        save_name = st.text_input("è¾“å…¥ä¿å­˜åç§°", placeholder="ä¾‹å¦‚ï¼šç‰¹æ–¯æ‹‰2024å¤ç›˜_V1")
                    with col_save_2:
                        st.write("") 
                        st.write("") 
                        if st.button("â˜ï¸ åŒæ­¥åˆ°äº‘ç«¯", type="primary"):
                            if not USE_CLOUD:
                                st.error("âŒ æœªé…ç½® AWSï¼Œæ— æ³•ä¸Šä¼ ã€‚è¯·æ£€æŸ¥ secrets.toml")
                            else:
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                safe_name = "".join([c for c in save_name if c.isalnum() or c in (' ', '_', '-')]).strip()
                                filename = f"{timestamp}_{ticker}_{safe_name}.json" if safe_name else f"{timestamp}_{ticker}.json"
                                cloud_path = f"{HISTORY_DIR}/{filename}"
                                
                                try:
                                    with st.spinner("ğŸš€ æ­£åœ¨ä¸Šä¼ åˆ° AWS S3..."):
                                        json_str = fig.to_json()
                                        with fs.open(cloud_path, "w") as f:
                                            f.write(json_str)
                                    st.success(f"âœ… äº‘ç«¯åŒæ­¥æˆåŠŸ: {filename}")
                                except Exception as e:
                                    st.error(f"ä¸Šä¼ å¤±è´¥: {e}")

                except Exception as e:
                    import traceback
                    st.error(f"ç»˜å›¾æŠ¥é”™: {e}")
                    st.text(traceback.format_exc())
        else:
            if data_source != "Yahoo Finance (å®ç›˜æ•°æ®)": st.warning("âš ï¸ æ•°æ®ä¸ºç©º")
    else:
        st.info("ğŸ‘ˆ è¯·ä¸Šä¼  Excel æ–‡ä»¶æˆ–é€‰æ‹©æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼")

# ==============================================================================
# å†å²è®°å½•æŸ¥çœ‹æ¨¡å¼ (äº‘ç«¯ç‰ˆ)
# ==============================================================================
elif app_mode == "ğŸ“‚ æµè§ˆå†å²è®°å½• (äº‘ç«¯)":
    st.title("â˜ï¸ äº‘ç«¯å›¾è¡¨æ¡£æ¡ˆé¦†")
    st.markdown("---")
    
    if not USE_CLOUD:
        st.error("âŒ æœªè¿æ¥ AWS S3ã€‚è¯·åœ¨ .streamlit/secrets.toml ä¸­é…ç½®å¯†é’¥ã€‚")
        st.stop()

    st.sidebar.header("ğŸ” æŸ¥æ‰¾ä¸ç­›é€‰")
    
    # 1. è·å–æ‰€æœ‰äº‘ç«¯æ–‡ä»¶
    try:
        # fs.glob è¿”å›çš„æ˜¯å®Œæ•´è·¯å¾„ list
        raw_files = fs.glob(f"{HISTORY_DIR}/*.json")
        
        # è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯ä»¥ä¾¿æŒ‰æ—¶é—´æ’åº
        file_details = []
        for f_path in raw_files:
            info = fs.info(f_path)
            # S3 info åŒ…å« LastModified
            file_details.append({
                'path': f_path,
                'name': os.path.basename(f_path),
                'time': info.get('LastModified', datetime.now())
            })
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—
        file_details.sort(key=lambda x: x['time'], reverse=True)
        
        if not file_details:
            st.info("ğŸ“­ äº‘ç«¯æš‚æ— è®°å½•ã€‚è¯·åœ¨â€œç”Ÿæˆæ–°å›¾è¡¨â€æ¨¡å¼ä¸‹ä¿å­˜ã€‚")
        else:
            # 2. æœç´¢åŠŸèƒ½
            search_term = st.sidebar.text_input("æœç´¢æ–‡ä»¶å/è‚¡ç¥¨ä»£ç ", "")
            
            # è¿‡æ»¤
            filtered_files = [f for f in file_details if search_term.lower() in f['name'].lower()]
            
            if not filtered_files:
                st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ã€‚")
            else:
                # 3. é€‰æ‹©æ–‡ä»¶
                # åˆ¶ä½œä¸‹æ‹‰èœå•é€‰é¡¹ï¼šåŒ…å«æ›´å‹å¥½çš„æ—¶é—´æ˜¾ç¤º
                options_map = {f['name']: f for f in filtered_files}
                selected_name = st.sidebar.selectbox("é€‰æ‹©è¦æŸ¥çœ‹çš„å›¾è¡¨", list(options_map.keys()))
                
                if selected_name:
                    selected_obj = options_map[selected_name]
                    full_path = selected_obj['path']
                    
                    # å‹å¥½çš„æ ‡é¢˜æ˜¾ç¤º
                    st.caption(f"ğŸ“… ä¸Šæ¬¡ä¿®æ”¹: {selected_obj['time']} | ğŸ“„ æ–‡ä»¶: {selected_name}")
                    
                    # 4. åŠ è½½å¹¶å±•ç¤º
                    try:
                        with st.spinner("æ­£åœ¨ä»äº‘ç«¯ä¸‹è½½..."):
                            with fs.open(full_path, 'r') as f:
                                fig_json = json.load(f)
                        
                        loaded_fig = go.Figure(fig_json)
                        st.plotly_chart(loaded_fig, use_container_width=True, config={
                            'scrollZoom': True,
                            'toImageButtonOptions': {'format': 'png', 'filename': selected_name.replace('.json', '')}
                        })
                        
                        st.markdown("---")
                        # 5. åˆ é™¤åŠŸèƒ½
                        if st.button("ğŸ—‘ï¸ ä»äº‘ç«¯åˆ é™¤æ­¤è®°å½•"):
                            try:
                                fs.rm(full_path)
                                st.success("âœ… å·²åˆ é™¤ï¼Œè¯·åˆ·æ–°é¡µé¢ã€‚")
                                st.rerun()
                            except Exception as e:
                                st.error(f"åˆ é™¤å¤±è´¥: {e}")
                                
                    except Exception as e:
                        st.error(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")
                        
    except Exception as e:
        st.error(f"è¯»å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")